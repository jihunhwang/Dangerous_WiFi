\documentclass[12pt]{article}
\usepackage{config}


\begin{document}
\noindent \textbf{CS 688 Probabilistic Graphical Models, Spring 2021 \hfill Assignment \#4}\\
\; \hfill Hwang, Jihun

\hrulefill

\begin{problem}{1 (Derivation of conditional distribution)}
Derive a formula for $p(y_i=1|y_{-i}, b, w)$.
\end{problem}

\newcommand{\nb}[1]{\mathrm{nb}(#1)}
\newcommand{\pairs}{\mathrm{pairs}}

\begin{proof}
By the Bayes' rule,
\begin{align*}
    p(y_i=1|y_{-i}, b, w)
    & = \frac{p(y_i=1, y_{-i} \mid  b, w)}{p(y_i=1, y_{-i} \mid  b, w) + p(y_i=-1, y_{-i} \mid  b, w)}
\end{align*}
Note the following
\begin{align*}
    & p(y_i, y_{-i} \mid  b, w) \\
    & = \frac{1}{Z} \prod_{k=1}^d \exp(b_k y_k) \prod_{(k,j) \in \pairs} \exp(w_{kj} y_k y_j) \\
    & = \frac{1}{Z} \underbrace{\left(\exp(b_i y_i) \prod_{(i, j) \in \pairs} \exp(w_{ij} y_i y_j) \right)}_{\text{When } k = i} \underbrace{\left( \prod_{k=1, k\neq i}^d \exp(b_j y_j) \prod_{(k,j) \in \pairs} \exp(w_{kj} y_k y_j) \right)}_{=: P(i)} \\
    & = \frac{1}{Z} P(i) \exp(b_i y_i) \left(\prod_{j \in \nb{i}} \exp(w_{ij} y_i y_j)\right) 
\end{align*}
Therefore,
\begin{align*}
    p(y_i=1 \mid y_{-i}, b, w)
    & = \frac{p(y_i=1, y_{-i} \mid  b, w)}{p(y_i=1, y_{-i} \mid  b, w) + p(y_i=-1, y_{-i} \mid  b, w)} \\
    & = \frac{\exp(b_i) \left(\prod_{j \in \nb{i}} \exp(w_{ij} y_j)\right)}{\exp(b_i ) \left(\prod_{j \in \nb{i}} \exp(w_{ij} y_j)\right) + \exp(-b_i) \left(\prod_{j \in \nb{i}} \exp(-w_{ij} y_j)\right)} \\
    & = \frac{1}{1+\exp(-2b_i) \prod_{j \in \nb{i}} \exp(-2 w_{ij} y_j)} \\
    & = \frac{1}{1+\exp\left(-2b_i - 2 \sum_{j \in \nb{i}} w_{ij} y_j \right)} \\
    & = \boxed{\sigma\left( 2b_i + 2 \sum_{j \in \nb{i}} w_{ij} y_j \right)}
\end{align*}
\end{proof}


\end{document}
